#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ¯”è¼ƒè¡¨ç¤ºã‚³ãƒ³ãƒãƒ¼ãƒãƒ³ãƒˆ
"""

import streamlit as st
import plotly.graph_objects as go
import plotly.express as px
from plotly.subplots import make_subplots
import pandas as pd
from typing import Dict, Any

from webui.components.styles import create_model_card, create_metric_card

class ComparisonDisplay:
    """æ¯”è¼ƒçµæœè¡¨ç¤ºã‚¯ãƒ©ã‚¹"""
    
    @staticmethod
    def display_comparison_result(result: Dict[str, Any]):
        """æ¯”è¼ƒçµæœã®è¡¨ç¤º"""
        if result["status"] != "success":
            st.error(f"ã‚¨ãƒ©ãƒ¼: {result['message']}")
            return
        
        # çµæœãƒ‡ãƒ¼ã‚¿ã®å–å¾—
        base_result = result["results"]["base_model"]
        finetuned_result = result["results"]["finetuned_model"]
        comparison = result["comparison"]
        metrics = result.get("metrics", {})
        
        # ãƒãƒ¼ã‚¯ãƒ€ã‚¦ãƒ³ã§æ¯”è¼ƒçµæœã‚¨ãƒªã‚¢ã‚’ä½œæˆ
        st.markdown('<div class="comparison-result">', unsafe_allow_html=True)
        
        # 1. ãƒ¢ãƒ‡ãƒ«å‡ºåŠ›ã®ä¸¦åˆ—è¡¨ç¤º
        st.subheader("ğŸ“ ãƒ¢ãƒ‡ãƒ«å‡ºåŠ›æ¯”è¼ƒ")
        
        col1, col2 = st.columns(2)
        
        with col1:
            create_model_card(
                "ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«",
                base_result["text"],
                "base"
            )
        
        with col2:
            create_model_card(
                "ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿ãƒ¢ãƒ‡ãƒ«",
                finetuned_result["text"],
                "finetuned"
            )
        
        # 2. åŸºæœ¬ãƒ¡ãƒˆãƒªã‚¯ã‚¹è¡¨ç¤º
        st.subheader("âš¡ ãƒ‘ãƒ•ã‚©ãƒ¼ãƒãƒ³ã‚¹æŒ‡æ¨™")
        
        col1, col2, col3, col4 = st.columns(4)
        
        with col1:
            create_metric_card(
                f"{base_result['inference_time']:.2f}s",
                "ãƒ™ãƒ¼ã‚¹æ¨è«–æ™‚é–“"
            )
        
        with col2:
            create_metric_card(
                f"{finetuned_result['inference_time']:.2f}s",
                "FTæ¨è«–æ™‚é–“",
                -comparison["speed_improvement"]  # è² ã®å€¤ã§é«˜é€ŸåŒ–ã‚’è¡¨ç¾
            )
        
        with col3:
            create_metric_card(
                str(base_result['character_count']),
                "ãƒ™ãƒ¼ã‚¹æ–‡å­—æ•°"
            )
        
        with col4:
            improvement = (finetuned_result['character_count'] - base_result['character_count']) / base_result['character_count'] * 100 if base_result['character_count'] > 0 else 0
            create_metric_card(
                str(finetuned_result['character_count']),
                "FTæ–‡å­—æ•°",
                improvement
            )
        
        # 3. è©³ç´°ãƒ¡ãƒˆãƒªã‚¯ã‚¹åˆ†æ
        if metrics and "base_metrics" in metrics:
            st.subheader("ğŸ“Š è©³ç´°ãƒ¡ãƒˆãƒªã‚¯ã‚¹åˆ†æ")
            ComparisonDisplay._display_detailed_metrics(metrics)
        
        # 4. å¯è¦–åŒ–ãƒãƒ£ãƒ¼ãƒˆ
        st.subheader("ğŸ“ˆ å¯è¦–åŒ–åˆ†æ")
        ComparisonDisplay._display_comparison_charts(result)
        
        st.markdown('</div>', unsafe_allow_html=True)
    
    @staticmethod
    def _display_detailed_metrics(metrics: Dict[str, Any]):
        """è©³ç´°ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¡¨ç¤º"""
        base_metrics = metrics["base_metrics"]
        finetuned_metrics = metrics["finetuned_metrics"]
        improvements = metrics["improvements"]
        
        # ã‚¿ãƒ–ã§æ•´ç†
        tab1, tab2, tab3, tab4 = st.tabs([
            "ğŸ“ˆ åŸºæœ¬çµ±è¨ˆ", "ğŸˆ³ æ—¥æœ¬èªç‰¹æ€§", "âœ¨ è¨€èªå“è³ª", "ğŸ“– èª­ã¿ã‚„ã™ã•"
        ])
        
        with tab1:
            col1, col2 = st.columns(2)
            
            with col1:
                st.markdown("**ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«**")
                st.json(base_metrics["basic_stats"])
            
            with col2:
                st.markdown("**ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿**")
                st.json(finetuned_metrics["basic_stats"])
        
        with tab2:
            # æ—¥æœ¬èªæ–‡å­—ä½¿ç”¨ã®å¯è¦–åŒ–
            ComparisonDisplay._display_japanese_characteristics(
                base_metrics["japanese_characteristics"],
                finetuned_metrics["japanese_characteristics"]
            )
        
        with tab3:
            col1, col2, col3 = st.columns(3)
            
            with col1:
                keigo_improvement = improvements.get("keigo_improvement", 0)
                create_metric_card(
                    f"{finetuned_metrics['linguistic_quality']['keigo_usage_rate']:.1f}%",
                    "æ•¬èªä½¿ç”¨ç‡",
                    keigo_improvement
                )
            
            with col2:
                vocab_improvement = improvements.get("vocabulary_improvement", 0)
                create_metric_card(
                    f"{finetuned_metrics['linguistic_quality']['vocabulary_richness']:.1f}%",
                    "èªå½™è±Šå¯Œã•",
                    vocab_improvement
                )
            
            with col3:
                similarity = metrics.get("similarity", 0)
                create_metric_card(
                    f"{similarity:.1f}%",
                    "é¡ä¼¼åº¦"
                )
        
        with tab4:
            ComparisonDisplay._display_readability_metrics(
                base_metrics["readability"],
                finetuned_metrics["readability"]
            )
    
    @staticmethod
    def _display_japanese_characteristics(base_chars: Dict, finetuned_chars: Dict):
        """æ—¥æœ¬èªæ–‡å­—ç‰¹æ€§ã®å¯è¦–åŒ–"""
        # ãƒ‡ãƒ¼ã‚¿æº–å‚™
        categories = ['ã²ã‚‰ãŒãª', 'ã‚«ã‚¿ã‚«ãƒŠ', 'æ¼¢å­—']
        base_values = [
            base_chars['hiragana_count'],
            base_chars['katakana_count'],
            base_chars['kanji_count']
        ]
        finetuned_values = [
            finetuned_chars['hiragana_count'],
            finetuned_chars['katakana_count'],
            finetuned_chars['kanji_count']
        ]
        
        # ãƒ¬ãƒ¼ãƒ€ãƒ¼ãƒãƒ£ãƒ¼ãƒˆ
        fig = go.Figure()
        
        fig.add_trace(go.Scatterpolar(
            r=base_values,
            theta=categories,
            fill='toself',
            name='ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«',
            line_color='#FF6B6B'
        ))
        
        fig.add_trace(go.Scatterpolar(
            r=finetuned_values,
            theta=categories,
            fill='toself',
            name='ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿',
            line_color='#4ECDC4'
        ))
        
        fig.update_layout(
            polar=dict(
                radialaxis=dict(
                    visible=True,
                    range=[0, max(max(base_values), max(finetuned_values)) * 1.1]
                )
            ),
            showlegend=True,
            title="æ—¥æœ¬èªæ–‡å­—ç¨®ä½¿ç”¨æ¯”è¼ƒ",
            height=400
        )
        
        st.plotly_chart(fig, use_container_width=True)
    
    @staticmethod
    def _display_readability_metrics(base_readability: Dict, finetuned_readability: Dict):
        """èª­ã¿ã‚„ã™ã•ãƒ¡ãƒˆãƒªã‚¯ã‚¹ã®è¡¨ç¤º"""
        col1, col2 = st.columns(2)
        
        with col1:
            st.metric(
                "å¹³å‡æ–‡é•·ï¼ˆãƒ™ãƒ¼ã‚¹ï¼‰",
                f"{base_readability['avg_sentence_length']:.1f}æ–‡å­—"
            )
            st.metric(
                "æ–‡é•·åˆ†æ•£ï¼ˆãƒ™ãƒ¼ã‚¹ï¼‰",
                f"{base_readability['sentence_length_variance']:.1f}"
            )
        
        with col2:
            improvement = (
                (finetuned_readability['avg_sentence_length'] - base_readability['avg_sentence_length'])
                / base_readability['avg_sentence_length'] * 100
                if base_readability['avg_sentence_length'] > 0 else 0
            )
            
            st.metric(
                "å¹³å‡æ–‡é•·ï¼ˆFTï¼‰",
                f"{finetuned_readability['avg_sentence_length']:.1f}æ–‡å­—",
                f"{improvement:+.1f}%"
            )
            
            variance_improvement = (
                (finetuned_readability['sentence_length_variance'] - base_readability['sentence_length_variance'])
                / base_readability['sentence_length_variance'] * 100
                if base_readability['sentence_length_variance'] > 0 else 0
            )
            
            st.metric(
                "æ–‡é•·åˆ†æ•£ï¼ˆFTï¼‰",
                f"{finetuned_readability['sentence_length_variance']:.1f}",
                f"{variance_improvement:+.1f}%"
            )
    
    @staticmethod
    def _display_comparison_charts(result: Dict[str, Any]):
        """æ¯”è¼ƒãƒãƒ£ãƒ¼ãƒˆã®è¡¨ç¤º"""
        base_result = result["results"]["base_model"]
        finetuned_result = result["results"]["finetuned_model"]
        
        # æ¨è«–æ™‚é–“æ¯”è¼ƒ
        col1, col2 = st.columns(2)
        
        with col1:
            # æ¨è«–æ™‚é–“ãƒãƒ¼ãƒãƒ£ãƒ¼ãƒˆ
            fig_time = go.Figure(data=[
                go.Bar(
                    name='æ¨è«–æ™‚é–“',
                    x=['ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«', 'ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿'],
                    y=[base_result['inference_time'], finetuned_result['inference_time']],
                    marker_color=['#FF6B6B', '#4ECDC4']
                )
            ])
            
            fig_time.update_layout(
                title="æ¨è«–æ™‚é–“æ¯”è¼ƒ",
                yaxis_title="æ™‚é–“ï¼ˆç§’ï¼‰",
                height=300
            )
            
            st.plotly_chart(fig_time, use_container_width=True)
        
        with col2:
            # æ–‡å­—æ•°æ¯”è¼ƒ
            fig_chars = go.Figure(data=[
                go.Bar(
                    name='æ–‡å­—æ•°',
                    x=['ãƒ™ãƒ¼ã‚¹ãƒ¢ãƒ‡ãƒ«', 'ãƒ•ã‚¡ã‚¤ãƒ³ãƒãƒ¥ãƒ¼ãƒ‹ãƒ³ã‚°æ¸ˆã¿'],
                    y=[base_result['character_count'], finetuned_result['character_count']],
                    marker_color=['#FF6B6B', '#4ECDC4']
                )
            ])
            
            fig_chars.update_layout(
                title="å‡ºåŠ›æ–‡å­—æ•°æ¯”è¼ƒ",
                yaxis_title="æ–‡å­—æ•°",
                height=300
            )
            
            st.plotly_chart(fig_chars, use_container_width=True)

# ã‚°ãƒ­ãƒ¼ãƒãƒ«ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹
comparison_display = ComparisonDisplay()
